{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31d2c374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import requests\n",
    "import fitz \n",
    "import os\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "max_input_tokens = 2048\n",
    "\n",
    "class ModelManager:\n",
    "    _model = None\n",
    "    _tokenizer = None\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, model_name, cache_dir=\"./cache\", save_dir=\"./saved_model\"):\n",
    "        \"\"\"\n",
    "        Loads the model and tokenizer either from a saved directory or from Hugging Face.\n",
    "\n",
    "        Args:\n",
    "            model_name (str): The name of the model to load.\n",
    "            cache_dir (str, optional): Directory for caching model files. Defaults to \"./cache\".\n",
    "            save_dir (str, optional): Directory to check for saved models. Defaults to \"./saved_model\".\n",
    "\n",
    "        Returns:\n",
    "            tuple: The model and tokenizer.\n",
    "        \"\"\"\n",
    "        # Check if the model and tokenizer are already loaded\n",
    "        if cls._model is None or cls._tokenizer is None:\n",
    "            if os.path.exists(save_dir):\n",
    "                print(\"Loading model and tokenizer from saved files...\")\n",
    "                cls._tokenizer = AutoTokenizer.from_pretrained(save_dir)\n",
    "                cls._model = AutoModelForSeq2SeqLM.from_pretrained(save_dir).to(device)\n",
    "            else:\n",
    "                print(\"Loading model and tokenizer from Hugging Face...\")\n",
    "                cls._tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "                cls._model = AutoModelForSeq2SeqLM.from_pretrained(model_name, cache_dir=cache_dir, torch_dtype=torch.float32).to(device)\n",
    "                # Save the model and tokenizer\n",
    "                cls._model.save_pretrained(save_dir)\n",
    "                cls._tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "        return cls._model, cls._tokenizer\n",
    "\n",
    "# PDFExtractor class to handle PDF text extraction\n",
    "class PDFExtractor:\n",
    "    @staticmethod\n",
    "    def extract_text_from_pdf(pdf_source: str) -> str:\n",
    "        \"\"\"\n",
    "        Extracts text from a PDF document, either from a URL or local file.\n",
    "\n",
    "        Args:\n",
    "            pdf_source (str): The URL or local path of the PDF.\n",
    "\n",
    "        Returns:\n",
    "            str: The extracted text from the PDF.\n",
    "\n",
    "        Raises:\n",
    "            Exception: If the PDF cannot be fetched or processed.\n",
    "        \"\"\"\n",
    "        print(\"Starting to extract text from the PDF...\")\n",
    "        try:\n",
    "            if pdf_source.startswith(\"http\"):\n",
    "                # Ensure the URL points to a direct PDF file (not a webpage)\n",
    "                if not pdf_source.endswith('.pdf'):\n",
    "                    raise Exception(\"The URL does not point to a PDF file.\")\n",
    "                \n",
    "                response = requests.get(pdf_source)\n",
    "                response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "                doc = fitz.open(stream=response.content, filetype=\"pdf\")\n",
    "            else:\n",
    "                doc = fitz.open(pdf_source)\n",
    "\n",
    "            text = \" \".join(page.get_text(\"text\") for page in doc)\n",
    "            doc.close()\n",
    "            print(\"Text extraction from PDF completed.\")\n",
    "            return text.strip()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            raise Exception(f\"Failed to fetch the PDF from URL: {e}\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error processing the PDF: {e}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess_text(text: str) -> str:\n",
    "        \"\"\"\n",
    "        Preprocesses the extracted text by normalizing the whitespace.\n",
    "\n",
    "        Args:\n",
    "            text (str): The raw extracted text.\n",
    "\n",
    "        Returns:\n",
    "            str: The preprocessed text with normalized whitespace.\n",
    "        \"\"\"\n",
    "        print(\"Starting text preprocessing...\")\n",
    "        text = \" \".join(text.split())  # Normalize whitespace to single spaces\n",
    "        print(\"Text preprocessing completed.\")\n",
    "        return text\n",
    "\n",
    "# QAGenerator class to handle question-answer generation\n",
    "class QAGenerator:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        \"\"\"\n",
    "        Initializes the QAGenerator with the model and tokenizer.\n",
    "\n",
    "        Args:\n",
    "            model: The preloaded model.\n",
    "            tokenizer: The preloaded tokenizer.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def answer_question_from_document(self, document_text: str, question: str) -> str:\n",
    "        \"\"\"\n",
    "        Generates an answer to a question based on the provided document text.\n",
    "\n",
    "        Args:\n",
    "            document_text (str): The text extracted from the document.\n",
    "            question (str): The question to be answered.\n",
    "\n",
    "        Returns:\n",
    "            str: The generated answer.\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"You are an expert assistant trained to answer questions based on real estate documents. \n",
    "            Your task is to provide the most accurate and specific answer, strictly based on the content of the provided document. \n",
    "\n",
    "            Please follow these rules:\n",
    "            1. **Provide direct quotes** from the document. Do not paraphrase or modify the content in any way.\n",
    "            2. **Avoid speculation**. Only answer based on the exact information available in the document. Do not infer or invent any details.\n",
    "            3. **Maintain precision**. Ensure that numbers, facts, and all details are quoted exactly as they appear.\n",
    "            4. If the information required to answer the question is missing from the document, **say \"Information not available in the document\"**.\n",
    "\n",
    "            Document:\n",
    "            \\\"\\\"\\\"{document_text}\\\"\\\"\\\" \n",
    "\n",
    "            Question:\n",
    "            {question}\n",
    "\n",
    "            Answer:\n",
    "            \"\"\"\n",
    "\n",
    "        # Tokenize the input text without truncation or splitting\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Call the model to generate the answer\n",
    "        outputs = self.model.generate(\n",
    "            **inputs,\n",
    "            max_length=100,  # Longer responses if necessary\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            top_k=50,  # Limit top-k to reduce repetitions\n",
    "            repetition_penalty=1.5,\n",
    "            no_repeat_ngram_size=5,\n",
    "            length_penalty=1.0,\n",
    "            num_beams=5,\n",
    "            early_stopping=True,\n",
    "            pad_token_id=self.tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "        # Decode the generated answer\n",
    "        generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "        return generated_text\n",
    "\n",
    "    def generate_qa_dictionary(self, document_text: str, questions: list) -> dict:\n",
    "        \"\"\"\n",
    "        Generates answers for a list of questions based on the document text.\n",
    "\n",
    "        Args:\n",
    "            document_text (str): The text extracted from the document.\n",
    "            questions (list): A list of questions to be answered.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary where keys are questions and values are answers.\n",
    "        \"\"\"\n",
    "        print(\"Generating answers for all questions...\")\n",
    "        qa_dict = {}\n",
    "        for question in questions:\n",
    "            answers = set()  # Use a set to avoid duplicate answers\n",
    "            answer = self.answer_question_from_document(document_text, question)\n",
    "            if answer.strip() != \"Information not available in the document.\":\n",
    "                answers.add(answer.strip())  # Add only unique answers\n",
    "            qa_dict[question] = \" \".join(answers) if answers else \"Information not available in the document.\"\n",
    "        print(\"Answers generated successfully.\")\n",
    "        return qa_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41c9971c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the main flow...\n",
      "Loading model and tokenizer from saved files...\n",
      "Starting to extract text from the PDF...\n",
      "Text extraction from PDF completed.\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Generating answers for all questions...\n",
      "Answers generated successfully.\n",
      "Q: What is the delivery date for the South Tower of UNA CLUB?\n",
      "A: 2027\n",
      "\n",
      "Q: What is the delivery date for the North Tower of UNA CLUB?\n",
      "A: 2029\n",
      "\n",
      "Q: Who is the developer of UNA CLUB?\n",
      "A: Fortune International and Ch√¢teau Group\n",
      "\n",
      "Q: Where is the UNA CLUB project located?\n",
      "A: Sunny Isles Beach\n",
      "\n",
      "Q: What is the starting price of UNA CLUB residences?\n",
      "A: $4,500,000\n",
      "\n",
      "Q: What is the price range for residences in Brickell Home Luxury?\n",
      "A: Starting at $8,000,000\n",
      "\n",
      "Q: How many stories does the Brickell Home Luxury building have?\n",
      "A: 25\n",
      "\n",
      "Q: How many residences are there in Brickell Home Luxury?\n",
      "A: 56\n",
      "\n",
      "Q: What is the size range of the residences in Brickell Home Luxury?\n",
      "A: 3 to 8 bedrooms\n",
      "\n",
      "Q: Who is responsible for the architecture of Brickell Home Luxury?\n",
      "A: Skidmore, Owings & Merrill\n",
      "\n",
      "Q: What is the price range for residences in Brickell Home?\n",
      "A: Starting at $8,000,000\n",
      "\n",
      "Q: How many stories does the Brickell Home building have?\n",
      "A: 25\n",
      "\n",
      "Q: How many residences are there in Brickell Home?\n",
      "A: 73\n",
      "\n",
      "Q: What is the size range of the residences in Brickell Home?\n",
      "A: 2,100 to 6,700 square feet\n",
      "\n",
      "Q: Who is the developer of Brickell Home?\n",
      "A: Mast Capital\n",
      "\n",
      "Q: What is the price range for residences in Bayfront Residences?\n",
      "A: Starting at $9,000,000\n",
      "\n",
      "Q: How many stories does the Bayfront Residences building have?\n",
      "A: 18\n",
      "\n",
      "Q: How many residences are there in Bayfront Residences?\n",
      "A: 49\n",
      "\n",
      "Q: What is the size range of the residences in Bayfront Residences?\n",
      "A: Floor plans starting at 2,400 up to 7,000 Sq. Ft.\n",
      "\n",
      "Q: What amenities are available at Bayfront Residences?\n",
      "A: Beach Service Expansive Pool Decks\n",
      "\n",
      "Main flow completed.\n"
     ]
    }
   ],
   "source": [
    "# Main flow\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    This is the main execution flow for the program.\n",
    "    It loads the model and tokenizer, extracts and preprocesses text from a PDF document,\n",
    "    generates answers to a set of predefined questions, and prints the results.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Starting the main flow...\")  # Added print statement\n",
    "    \n",
    "    # Load model and tokenizer\n",
    "    model, tokenizer = ModelManager.load(\"google/flan-t5-large\")\n",
    "    \n",
    "    # URL of the PDF document to extract text from\n",
    "    github_pdf_url = \"https://raw.githubusercontent.com/SAN1713911S/million-luxury-docs-qa/main/Million%20Luxury%20Document.pdf\"\n",
    "\n",
    "    # Extract and preprocess text from the PDF document\n",
    "    document = PDFExtractor.extract_text_from_pdf(github_pdf_url)\n",
    "    document_text = PDFExtractor.preprocess_text(document)\n",
    "\n",
    "    # Create an instance of QAGenerator\n",
    "    qa_generator = QAGenerator(model, tokenizer)\n",
    "\n",
    "    # List of questions to generate answers for\n",
    "    questions = [\n",
    "        # Questions for UNA CLUB\n",
    "        \"What is the delivery date for the South Tower of UNA CLUB?\",\n",
    "        \"What is the delivery date for the North Tower of UNA CLUB?\",\n",
    "        \"Who is the developer of UNA CLUB?\",\n",
    "        \"Where is the UNA CLUB project located?\",\n",
    "        \"What is the starting price of UNA CLUB residences?\",\n",
    "\n",
    "        # Questions for BRICKELL HOME LUXURY\n",
    "        \"What is the price range for residences in Brickell Home Luxury?\",\n",
    "        \"How many stories does the Brickell Home Luxury building have?\",\n",
    "        \"How many residences are there in Brickell Home Luxury?\",\n",
    "        \"What is the size range of the residences in Brickell Home Luxury?\",\n",
    "        \"Who is responsible for the architecture of Brickell Home Luxury?\",\n",
    "\n",
    "        # Questions for BRICKELL HOME\n",
    "        \"What is the price range for residences in Brickell Home?\",\n",
    "        \"How many stories does the Brickell Home building have?\",\n",
    "        \"How many residences are there in Brickell Home?\",\n",
    "        \"What is the size range of the residences in Brickell Home?\",\n",
    "        \"Who is the developer of Brickell Home?\",\n",
    "\n",
    "        # Questions for BAYFRONT RESIDENCES\n",
    "        \"What is the price range for residences in Bayfront Residences?\",\n",
    "        \"How many stories does the Bayfront Residences building have?\",\n",
    "        \"How many residences are there in Bayfront Residences?\",\n",
    "        \"What is the size range of the residences in Bayfront Residences?\",\n",
    "        \"What amenities are available at Bayfront Residences?\"\n",
    "    ]\n",
    "\n",
    "    # Generate answers for all the questions\n",
    "    qa_dictionary = qa_generator.generate_qa_dictionary(document_text, questions)\n",
    "\n",
    "    # Print the questions and their corresponding answers\n",
    "    for q, a in qa_dictionary.items():\n",
    "        print(f\"Q: {q}\\nA: {a}\\n\")\n",
    "    \n",
    "    print(\"Main flow completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
